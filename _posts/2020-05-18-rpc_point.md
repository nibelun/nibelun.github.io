---
title: 一次RPC的遭遇与思考
date: 2020-05-18 16:00:30 +0800
categories: [refine]
tags: [refine]
seo:
  date_modified: 2020-05-18 16:00:30 +0800

---

# 事情背景

在某次工作中，我与另一个团队产生了工作上的交集合作。

我们需要给对方提供一个HTTP服务接入，作为他们的服务上游。但对方由于团队要求，他们的所有上游服务，接入时都必须使用一套内部自研的RPC框架进行。

在给对方提供服务接入的过程中，对于这套RPC框架的使用过程中，我感受到了一股巨大的违和感，期间我尝试过用各种可能兼容的写法，尝试过于框架维护的团队进行沟通尝试让他们给与一些技术支持，甚至在项目的过程中考虑过放弃使用这套框架。

但由于项目Deadline与对方的强硬要求，我不得不选择了退让，最后使用了一种十分hack且后续无法正常拓展维护的写法以结束项目。

但不出所料，没过多久又有同事遇到了我之前遇到的一样的问题，无奈之下我只能告诉他我当时的应付精力让他们自行进行抉择，而这让我又一次对这个事情产生了新的思考。

# 系统交互细节

现有A、B和C共3个服务，A服务即上游服务，为B服务提供一些基础数据，使用HTTP协议交互，数据格式为JSON结构，B金座proxy转发后给C端。

转发的数据结构有如下

```
{
    "errno": 0,
    "errmsg": "",
    "data": {
        "key_1": {
            ...
        },
        "key_2": {
            ...
        },
        ...
        "key_n": {
            ...
        }
    }
}
```

以上结构值得详细说明的有两点：

1.在上述的结构中，data的值类型为object，内部可能存在n个不同的键，且返回的时机也不一样，这代表`key_1`乃至`key_n`的返回均是不固定的。

2.`key_1`至`key_n`，不同的键，其值再对应不同的具体结构，并且有一部分结构还可能随机变化，例如下面的例子

```
{
    "key_1": {
        "title": "xxx",
        "time": "xxx-xxx-xxx xx:xx:xx",
        "value": 123，
        “log”: {
            ...
        }
    }
}
```

`key_1.log`为一个不稳定的结构，这个结构里的数据不涉及任何业务上的逻辑，仅作为统计数据而已，中间层对内部也不做任何加工，拿到的数据会原封不动的透传到下游。

A与B服务的交互基于RPC框架进行，B与C则是普通的HTTP交互.

因此，我们可以把ABC三个服务看成如下关系。

![4E1BBD4E-FF54-40A2-BE14-7CAD0A5D3C17.png](assets/img/post/4E1BBD4E-FF54-40A2-BE14-7CAD0A5D3C17.png)

# 关于RPC

在工作中，我或多或少接触过一些RPC框架。

过去在上一家公司，PHP业务线几乎被RAL所占据——一个公司内部开源的动态PHP拓展库，在支持常见的HTTP协议基础上，也支持较为古老的与C家族服务的MCPACK等内部协议的调用框架。期间在开发GO相关的WEB的RPC组件时，也或多或少参考了RAL的设计思路。

开源框架以GRPC比较出名，但由于RRPC对使用有一定的门槛，以及protobuf协议在业务层调试存在一定成本，因此尚未广泛的适用于业务层这类迭代频繁的项目中。

较为有规模的企业，为了更好的构建服务网格（service mesh）来治理服务，通常会自行封装RPC框架并搭载服务发现，因此除了调用的封装，一个完整的RPC框架还同时包括服务注册、服务发现、调度、负载均衡甚至探活等职能，借用别人的一张比较合理的图，大致关系如下。

![921E0B02-FB82-4E92-AE89-A2B6CCEE11E7.png](assets/img/post/921E0B02-FB82-4E92-AE89-A2B6CCEE11E7.png)

至于为何大家提倡使用RPC？这个问题仁者见仁智者见智，RPC的诞生固然有他的需求背景。

早年间我第一次”真正“接触RPC时，惊叹于这种框架的设计思路，作为业务侧的研发，我可以不需要去关注一些十分复杂的交互协议，这些封装完全通过抽象做成同一种实现，RPC则实现了这一点，与此同时，我也不需要关心使用我的C端使用的是哪种语言，只要遵循事先定义的固定Scheme，我可以快速的生成多种语言的调用SDK——而这对我的服务使用方也是福音，他们不用再花额外的经历去开发一个专门针对我们的客户端调用封装。

# 我的困惑

理想状态下的服务调用是非常美好的，但现实情况是，RPC的使用仍有诸多门槛。

#### 协议拓展

使用GRPC时，提倡先定义PB或IDL，在Message与Service定义完毕后，通过组件进行SDK与SERVE代码自动生成。这种工作形式对于新服务而言并没有太大的问题，但对于老服务而言，特别是上游服务为HTTP协议的情况下，就会变得很尴尬。

HTTP协议是一个非常自由的协议，你既可以在使用Header来标记你的资源METE，也可以像Json一样将Scheme和Data打包到一起全部传给下游，至于如何解析以及需要哪些数据，由下游来自己定义，即便后续协议升级，例如添加了一些新的输出信息也非常容易拓展。

但若要事先对HTTP协议进行Scheme分离，就意味着这会牺牲掉它原有的易拓展的特性。还是以ABC三个服务为例，B服务只是一个Proxy转发。若不使用RPC框架时，C服务可以直接从payload中拿到完整的A服务的所有数据，具体如何使用取决于C；倘若A有一天新增了功能，多了一些额外的输出，C也可以很快速方便的拿到。

![D5D354D2-0D7E-4E19-85DE-6FD596F7BD12.png](D5D354D2-0D7E-4E19-85DE-6FD596F7BD12.png)

但若AC不为直接交互，中间多出了非常多的反向代理或者路由，且中间层均基于RPC进行（LVS不做讨论），则协议的拓展成本将会变得很高（中间层需要升级协议并更新调用），RPC的优势没办法得到体现。

![30B3DA96-595C-4BEF-ACD6-874DF1D8DFE8.png](30B3DA96-595C-4BEF-ACD6-874DF1D8DFE8.png)

在老版本的PB中，无法识别的数据在解析和透传时会被忽略；3.5以上的版本则对`unknow fields`进行了支持，但即便如此，这也是一种对协议拓展的另类支持方式。

[https://developers.google.com/protocol-buffers/docs/proto3#unknowns](https://developers.google.com/protocol-buffers/docs/proto3#unknowns)

#### 协议兼容

刚才有提到，RPC的使用提倡实体数据与定义进行分离，但这种实现方式本质上和一些协议相违背，例如大众常用的JSON——定义与数据混在一起。

当然有人会说，JSON也能数显Scheme分离写法，例如：

```
["1","this is en error",null]

<?php
$this->errno = data[0]
$this->errmsg = data[1]
$this->data = data[2]
```

这种书写方式破坏了JSON的数据可读优势，因此不再对这种例子进行拓展。

倘若有一个极其不固定的结构，这种结构不做任何形式的拓展，只是进行透传，则用PB或IDL书写即为尴尬。

```
{
    "log": {
        "key_1": 1,
        "key_2": false,
        "key_3": "asd"
    }
}
```

log内的结构不固定，拓展性极强，书写idl时也无法对所有KV进行枚举，中间每一个服务在拿到这个结构时可能也会各自添油加醋，则除了把整个结构序列化别无他法。

```
{
    "log": {\"key_1\":1,\"key_2\":false,\"key_3\":\"asd\"}
}
```

曾经我也尝试过使用Oneof关键字，但几经思考后，觉得oneof并不是为了解决这个问题而存在的。

```
message Log {
  oneof test_oneof {
     int32 key_1 = 1;
     bool key_2 2;
     string key_3 = 3;
  }
}
```

但这种方式把整个数据长度拉大的同事，上下游也额外增加了一次无意义的编码和解码流程，可以说是为了适应框架而双输的局面。若对于一个新服务，我们可以重新优化log的透传和使用，但更有可能的场景式，这是一个已经在线上跑了多年的服务，这一小小的更改，可能去牵扯到一大片报表与客户端的调整。

除了以上方案，我也尝试过如下书写方案——RPC不对返回做任何反序列化，将所有结果当做字符串；反序列的工作交由C端业务自己实现。

```
service SearchService {
  rpc Search (SearchRequest) returns (string);
}
```

这是在不改变服务的情况下，我能想到的最兼容的写法。遗憾的是，这并不是使用RPC的初衷，虽然程序用这种方式能跑通，但失去了使用框架的意义。

同时，由于公司内部的RPC框架的限制（不论任何返回，哪怕content-type不是json，都做了一次json_decode），也同样使得直接以string作为返回无法实现。

**最终只能在特定的场景下，以枚举所有可能用到的字段，来临时解决了这个问题。**

#### 使用成本

这里的使用成本既有服务方，也有客户方。

对客户端而言，RPC框架的好处在于他们不需要关注交互的协议细节，也不需要额外的封装和维护调用的代码，只需要引入指定的代码库，更新到指定版本即可。

对服务方而言，协议的更新会变得比以往更为繁琐——本质上这是把客户端的封装工作集中到了服务提供方身上。除了编写新的协议文件外，服务侧的更新，客户端的更新，都会有额外的校验、发布工作。但其实这是一种好现象，通过使用测试框架，可以更好的保证服务更新造成的协议不兼容等问题，但这不意味着维护不需要投入额外的成本。

当然，对于一些从创建初就未使用RPC框架的服务，迁移是一个很痛苦的过程……除了服务管理的需要，或者不得不绑定使用SDK中的服务发现，我很难去寻找下游的收益点来推动别人使用我们迁移后的SDK。

# 关于JSON

我开始思考，出现使用困难问题的本质，实际上是协议的使用理念的差异。

我们通常更愿意使用JSON，多半是处于这个协议方便拓展、明文可读（数据体包含scheme）、有众多使用简单的库。

但实际上，和弱类型语言一样，方便是伴随着隐患的，尤其是不同语言对scheme的解释与实现。

比如我曾经遇到的一个非常尴尬的问题。在PHP里，`array`既能表示数组，在某些场合也能表示"对象"，因此PHP的`json_encode`在以下场景会有十分神奇的表现。

```
<?php

$b = array(1=>"test");
echo json_encode($b);
// 输出 {"1":"test"} 由于没有声明index:0的数据 因此1在序列化时被当做键来解释 于是这里$b被当做了object

$c = array(0=>"test");
echo json_encode($c);
// 输出 ["test"] 同$b一样的写法 这里$c却被当成了[]

```

同样的问题还有如下例子：

```
$a = array();
echo json_encode($a);
// 输出 [] 这里$a被当做了[]

$b = new StdClass();
echo json_encode($b);
// 输出 {} 这里$b被当做了{}
```

这种问题在输出的时候，若下游时强类型语言（例如C是Android时），则会变得尤为致命，虽然这并不是JSON协议本身而是语言的元数据结构问题。

至于反序列化，弱类型语言也存在部分问题，例如：

```
<?php

$a = '{"1": "asd"}';
$b = json_decode($a, 1);
var_dump($b["1"]);
var_dump($b[1]);

$c = '["","asd"]';
$b = json_decode($c, 1);
var_dump($b["1"]);
var_dump($b[1]);
```

同理JS也有如下例子：

```
JSON.parse('["","asd"]')[1]
JSON.parse('{"1":"asd"}')[1]
```

代码上的执行，以上4个输出的结果均相同，可实际上`$a`和`$c`所表达的是两套截然不同的数据，在反序列化的过程中，数据的部分含义被主观的“屏蔽”掉了。

以上问题本质上都是为了兼容语言本身的元数据结构，而对JSON做出的不同“解释”，这让我在后续使用JSON作为交互协议时变得十分敏感。

除了不同语言对SCHEME的解释方式不同，JSON本身也存在有解析的性能、以及数据体积较大的先天问题。

```
xxx-form-urlencode:
a=1&b=2&c[]=3

json:
{"a":1,"b":2,"c":[3]}
```

但比起每次拿着Scheme来反序列化传输的数据，我还是更愿意去直接使用JSON这种可读性更高的协议，如果没有性能的要求，或网络带宽瓶颈的情况下，这比相对局限的RPC而言会更加灵活。。

# 选择

业务场景决定技术选型。

同样是刀，砍骨刀、切菜刀、水果刀分别有着不同的用途，不论是拿砍骨刀来削果皮，还是用水果刀去切肉，这都是一个痛苦的过程。自己的技术项目是否真的适用RPC，取决于项目的适用场景，盲目的追求新技术栈，反而会可能让项目处于尴尬的境地。

在我的观点里，RPC是否适用，取决于实际场景的协议兼容性，背后的技术支持力度，以及我们对协议描述与更新的需求。对于一个仅仅只是普通输出JSON数据，且迭代十分频繁的服务而言，引入RPC框架有可能会因一系列更新、发布的流程，造成排期拉长与繁琐的额外问题，且并没有太大的收益，尤其是我所遇到的情况——协议定义不兼容。

若我现在构建的是一个从0到1的新服务，有大量的业务端，迭代不频繁，对并发要求特别高，那RPC无疑是我最好的选择。除此之外，我都应该要去思考引入RPC的代价我们是否可以承担。

# 推进

曾经，我也做过服务治理的工作，曾经，我也遇到过推动困难的情形，仔细思考后无疑是以下几个阻塞点：

> 人力不足或收益不明显——业务感知不到接入新技术栈的收益，反而觉得花费人力投入是一项无意义的成本。
> 
> 稳定性——业务侧将接入新服务视为一种风险，新的技术栈不一定足够成熟。
> 
> 不兼容——若仍旧遇到我当前遇到的这种问题，只能互相退让——要么推动方进行业务兼容，要么业务方进行整改。

但如今换位思考，我仍旧觉得推进RPC的使用是一个十分有意义的事情，不论是后续的服务治理，还是规范化约束业务线的协议制定方面。

而对于阻塞推动的问题，自我对技术领域的深入和理解而非盲从则是最为重要的方案，结合业务的痛点，来针对性举例做宣传，由边缘业务逐渐推动到核心业务，逐步完善文档与各种场景的兼容，是较为温和的推进形式。

以及，引入以为前辈让我印象很深刻的话，我始终坚信，一个优秀的框架，不仅仅需要帮助业务减少繁琐重复的工作，更重要的是，还需要引导业务如何更好地取组织代码、管理项目。